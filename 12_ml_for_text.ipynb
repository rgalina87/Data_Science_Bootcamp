{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Negative Reviews (BERT)\n",
    "(machine learning for texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Content\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [General information](#general)\n",
    "3. [Preparing Dataset](#prep)\n",
    "4. [Models](#models)\n",
    "5. [Training Best Model on Test Set](#test_set)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Introduction<a href='intro'></a>\n",
    "The goal is to train a model to automatically detect negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state = 123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    toxic_comm_dataset = pd.read_csv(\"toxic_comments.csv\")\n",
    "except:\n",
    "    toxic_comm_dataset = pd.read_csv(\"/datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## General information<a href='general'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     text  toxic\n96964   \"\\n EDIT: also, I'll go to that page, but sinc...      0\n4353    \" HJ Mitchell has no justification for claimin...      0\n113108  \"\\nThis isn't meant facetiously, but it might ...      0\n157090  If you can read, you know who and where.  190....      0\n80185   I have removed the Category:Lesbian, gay, bise...      0\n27962   \"\\n\\n Why is my article bad? \\n\\nHi Gilo,\\n\\nW...      0\n132813  Shoo! Complaining about something that I refac...      0\n80398   You're invited to Wikipedia Takes St. Louis! \\...      0\n94878   \"\\nWe should not change the F to lower case. T...      0\n8617    I dont care about kurds actually (i am neutral...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96964</th>\n      <td>\"\\n EDIT: also, I'll go to that page, but sinc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4353</th>\n      <td>\" HJ Mitchell has no justification for claimin...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>113108</th>\n      <td>\"\\nThis isn't meant facetiously, but it might ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>157090</th>\n      <td>If you can read, you know who and where.  190....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>80185</th>\n      <td>I have removed the Category:Lesbian, gay, bise...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27962</th>\n      <td>\"\\n\\n Why is my article bad? \\n\\nHi Gilo,\\n\\nW...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>132813</th>\n      <td>Shoo! Complaining about something that I refac...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>80398</th>\n      <td>You're invited to Wikipedia Takes St. Louis! \\...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94878</th>\n      <td>\"\\nWe should not change the F to lower case. T...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8617</th>\n      <td>I dont care about kurds actually (i am neutral...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comm_dataset.sample(10,random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic_comm_dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "text     0\ntoxic    0\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comm_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comm_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS6ElEQVR4nO3df6zdd33f8ecLO61H61BRbgNznMbOGCohkUgvo2ukxWNUIqKdVmlXrEtgZAFLmZqIwEjHSoD90Ajq1MxpYiYnGSwtSlQ53dhCSUvTGiMqbTXeMNAu3YjdKl5GLnRV7W52J/e9P8734otzHR/b53vfce7zIV197vl+zr3n80XOUx++937vSVUhSVp9L+legCStVQZYkpoYYElqYoAlqYkBlqQm67sX8EL1lre8pR5//PHuZUh6cchKB90Bn8Y3v/nN7iVIepEzwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxD9HOWM//P6Hupegc/Cln3tH9xK0BrkDlqQmBliSmhhgSWoyWoCT3JPkG0kqyWOnzG1I8uQwd++y49cmOZDkeJL9Sa4Zc06SOo29A37kNMc/BFy6/ECSDcCjwEbgduASYHeSdWPMzfY0JensjRbgqroNuPvU40muZhLDj5wydT2TQO6sqp3Ag8AWYNtIc5LUalWvASd5CfAAcB/wO6dMbxnGw8P49DBuHWlupfVtT7Ivyb7FxcUzno8knY/V/iHcTcDlwEPApuHYy5LMrfDcpbdxrlWao6p2VdV8Vc3Pza20JEmandW+EWMzMAd8edmxG4HjwGeGx0vXhpcCfRC4eIQ5SWo1WoCTvBV43fBwc5J3Af8O+Opw7Eom14EfBz4OfA14FrglyRHgZuAQsAe4aIQ5SWo15iWI9wN3DZ9fDdwPvL6qdlfVbuDzw9zXq+pLVXUMWACOAjuYhHOhqk6MMTfieUvSVEbbAVfVtjPM7+HkNdmlY3uBq07z/JnPSVIn74STpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqcloAU5yT5JvJKkkjw3HXp3kt5J8K8mRJJ9LcsWyr7k2yYEkx5PsT3LNmHOS1GnsHfAjpzzeNLzmh4FPAG8GHgBIsgF4FNgI3A5cAuxOsm6MufFOWZKms36sb1xVtyW5HLht2eHfrqrrlh4kuQG4cnh4PZNA3lFVO5O8ErgT2AZcPMLcEyOctiRNbVWvAVfVny19nmQeeDmwdzi0ZRgPD+PTw7h1pLnnSLI9yb4k+xYXF6c5JUk6Zy0/hEvyGuDTwCHg1tM9bRhrleaoql1VNV9V83Nzc6dZliTNxmiXIE4nyWuB3wSOA2+qqmeGqYPDeOkwblp2/OIR5iSp1WgBTvJW4HXDw81J3gU8yeSHYi8HPgi8Mckbq+oR4LPAs8AtSY4ANzPZIe8BLhphTpJajXkJ4v3AXcPnVwP3A1cAc8A64KPAw8MHVXUMWACOAjuYhHOhqk6MMTfieUvSVMb8LYhtp5n65PN8zV7gqtWak6RO3gknSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUZLQAJ7knyTeSVJLHlh2/NsmBJMeT7E9yTdecJHUaewf8yPIHSTYAjwIbgduBS4DdSdat9tzI5y1JZzRagKvqNuDuUw5fzySCO6tqJ/AgsAXY1jAnSa3Wr/LrbRnGw8P49DBuZbJLXc25J85++ZI0O90/hMsw1gtgjiTbk+xLsm9xcXGlp0jSzKx2gA8O46XDuGnZ8dWee46q2lVV81U1Pzc3d8aTkaTzMdoliCRvBV43PNyc5F3AfwKeBW5JcgS4GTgE7AEuWuU5SWo15g74/cBdw+dXA/cDPwwsAEeBHUziuFBVJ6rq2GrOjXjekjSV0XbAVbXteaavOs3X7F3NOUnq1P1DOElaswywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSk6kCnOQdSX5w2ePvT/Kj5/PCSd6T5FCS40kOJrl1OH5tkgPD8f1Jrln2NTOfk6Qu0+6APwH8lWWPfwz4wrm+aJJXA3cDfw68F7gIuCfJZuBRYCNwO3AJsDvJuiQbZj13ruuXpFlY/3yTSf4m8LeAAP8gyfXD1OuBY+fxukvhPwz8BnAT8ArgR5gE8o6q2pnklcCdwDbg4hHmnjiPc5Ck8/K8AWYS2ncCBVw3fCz51Lm+aFU9meQfAR8F/huTnfBNwObhKYeH8elh3MpkBzvrue8IcJLtwHaAyy677GxPS5LOypkuQexicukhwM8CbwDmgSuq6u3n+qJJ5oBbgf/KZIf9ZeBe4HtPfeow1krfZtZzVbWrquaran5ubu50y5ekmXjeHXBVPQM8A7wkyXom/1d+HUCSy6rqD8/xdf86sAn411X16SRXAf8M+L1h/tJh3DSMB5lcSpj1nCS1OdMlCACG31C4C9iw7HBN+/UreGoYb0zyDHDD8Pj3gWeBW5IcAW4GDgF7mPygbtZzktRm2t+C+CdMfuj268CvDh+fPdcXrap9wPuA7wbuG8afrqovAwvAUWAHk3AuVNWJqjo267lzXb8kzcK0O9hDwP1V9fFZvXBV/Tzw8ysc3wtcdZqvmfmcJHWZNsAHgDuT/EXgfw/HqqruHmdZkvTiN22A3zGMP7vsWDG5mUKSdA6mDfDfZ+Vf6ZIknaOpAlxVnxx5HZK05kz7a2hPrXC4quqKGa9HktaMaS9B/AAnL0H8BSa/vvZ/RlmRJK0R016C+PYtwkm+i8lNGf4tYUk6D9Neglj+93PXA98F/F3gPSOsSZLWhGkvQezjO38LIsB/nv1yJGntmDbAD3EywCcY7owbY0GStFZMew34ncM7SPzl4dDv+7cUJOn8TPuecD/E5E9FfnX4+N3hmCTpHE37mwz3Aa8CHgYeGT7/hbEWJUlrwbTXgOeBD1TVvQBJfhr4F6OtSpLWgGl3wH8EvDnJ1iRbmbwr8rfGW5YkvfhNuwO+n8lbBv3E8DjAB0dZkSStEdMG+JeARSY7X4BfAz43yookaY2Y9hLEbwCbq2qhqhaAH8QAS9J5mTbAm5jcfLHkDzj5LsOSpHMw7SWIp4B/mOQwk+u/7+PkOxtLks7BtAH+GPBvgc8MjwO8fZQVSdIaMe2tyL+Y5A+AHx8O/ceq+sJ4y5KkF79pd8BLb+2+d8S1SNKa4h9Vl6QmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJm0BTvJ9SR5K8sdJjibZOxy/NsmBJMeT7E9yzbKvmfmcJHXp3AH/G+AG4EHgPcD/SLIBeBTYCNwOXALsTrJujLlVO1NJWsHUfwtilob3lftJ4FPAB4ATVfVAkp9kEsg7qmpnklcCdwLbgItHmHtidc5Ykp6rawf82mF8A/CnwJ8m+RiwZTh+eBifHsatI819hyTbk+xLsm9xcfGsTkiSzlZXgL97GL8HeBvwReAOnrsjzzDWCt9j5nNVtauq5qtqfm5u7jRLl6TZaLkEwcm3N/pCVf1KkjngTZyM49LbHW0axoNMLiXMek6S2nQFeD/wFeBvJHk3cBNwgsk7brwXuCXJEeBmJrHeA1wEPDvjOUlq03IJoqoK+Cng68AvAC8H3lFVXwUWgKPADibhXKiqE1V1bNZzq3bCkrSCrh0wVfU14K+ucHwvcNVpvmbmc5LUxTvhJKmJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWrSGuAkG5I8maSS3DscuzbJgSTHk+xPcs2y5898TpK6dO+APwRcuvQgyQbgUWAjcDtwCbA7ybox5lbpHCVpRW0BTnI1kyB+ZNnh65kEcmdV7QQeBLYA20aak6Q2LQFO8hLgAeA+4HeWTW0ZxsPD+PQwbh1p7tR1bU+yL8m+xcXFqc9Hks5F1w74JuBy4CFg03DsZcBFpzwvw1grfI+Zz1XVrqqar6r5ubm5lVcuSTOyvul1NwNzwJeXHbsReGr4fOm68FKcDwIXjzAnSW26AvzLwFeHz69kch34ceCfA78C3JLkCHAzcAjYw2R3/OyM5ySpTcsliKr63araXVW7gc8Ph79eVV8EFoCjwA4m4VyoqhNVdWzWc6t1vpK0kq4d8LdV1R5OXpelqvYCV53muTOfk6Qu3b8HLElrlgGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElq0hLgJK9O8ltJvpXkSJLPJblimLs2yYEkx5PsT3LNsq+b+ZwkdenaAW8aXvvDwCeANwMPJNkAPApsBG4HLgF2J1k3xtyqna0krWB90+v+dlVdt/QgyQ3AlcD1TAJ5R1XtTPJK4E5gG3DxCHNPjH+qkrSylh1wVf3Z0udJ5oGXA3uBLcPhw8P49DBuHWnuOyTZnmRfkn2Li4tnc0qSdNZafwiX5DXAp4FDwK0rPWUYazXmqmpXVc1X1fzc3Nzpli1JM9F1CYIkrwV+EzgOvKmqnklycJi+dBg3DeNBJpcSZj0nSW1aApxkM7CHyaWHDwJvTPJG4N8DzwK3JDkC3Mxkd7wHuGiEOUlq03UJ4gpgDlgHfBR4GHi4qo4BC8BRYAeTcC5U1Ykx5lbtbCVpBS074Kraw8lrsafO7QWuWq05SerinXCS1MQAS1KTtt+CkNayP/ynXhG7EF32oa/M9Pu5A5akJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmaybASa5NciDJ8ST7k1zTvSZJa9uaCHCSDcCjwEbgduASYHeSda0Lk7SmrYkAA9czie7OqtoJPAhsAbZ1LkrS2ra+ewGrZMswHh7Gp4dxK/DE0pOSbAe2Dw+PJnlydZZ3wXgF8M3uRYwh//LvdS/hxeRF+++ED+dcv/LxqnrLqQfXSoBPtfS/Yi0/WFW7gF2rv5wLQ5J9VTXfvQ69sPnvZHpr5RLEwWG8dBg3nXJcklbdWtkBfxZ4FrglyRHgZuAQsKdxTZLWuDWxA66qY8ACcBTYwSTGC1V1onVhFx4vz2ga/juZUqrqzM+SJM3cmtgBS9ILkQGWpCYGWGfkbdw6kyT3JPlGkkryWPd6LhQGWM/L27h1Fh7pXsCFxgDrTLyNW2dUVbcBd3ev40JjgHUmz3cbt6TzYIB1tla8jVvS2TPAOhNv45ZGslZuRda58zZunVGStwKvGx5uTvIu4PNV9d8bl/WC551wOqMkfw24D3gN8DXg3VW1r3dVeiFJsge47pTDN1XVJ1d/NRcOAyxJTbwGLElNDLAkNTHAktTEAEtSEwMsSU0MsAQkeWmSjyR553l8j8v9a2A6G/4amgQkeQWwyOTmgW3n+D2+B/gJ4HBVfWGGy9OLlDtgaWLpxpLrhl3sR5PcneR/JvnjJJ9OsjnJ9yZ5avh4aZI7hue/HZgDHgZ+BiDJq5I8kmQxyZEkd3WdnF6YDLA08Y+H8feAn2Jy1997gF8HPgb8OPCpqjoK3ARcDtwPfAT4D1X1iyt8z08BbxvG9zHZYUvf5iUIiedegkiyD3g98NKqOp7ki8CPAhur6miSe4BbgT8Crqyq/5XkciZ/pOgzwN8B/gT4UlW9oeGUdAFwByxNnO1O5FXD+FLgZTNei9YIAyxN/Anw58BfSnID8BUm/318PMnPAD8C7B12v28D/jaTd4D4v8AnT32LpuFSxR5gPsm/SvLuJO9bvdPRhcAAS0BV/T/g54DvA36JSTx3MHlLpg8AjwE3JvkB4F7gvwB3AO9lEueV4noD8MvAjUxiPTfmOejC4zVgSWriDliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJanJ/wfqLJ0twO7t0wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_plot = sns.catplot(x='toxic', kind='count', data=toxic_comm_dataset, order=toxic_comm_dataset.toxic.value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "We have dataset with 159571 entries and to columns.<br>\n",
    "No missing data.<br>\n",
    "No duplicates.<br>\n",
    "For column toxic we need to do downsapling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing Dataset<a href='prep'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Tokenization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = toxic_comm_dataset['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4950"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(map(len, tokenized))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to delete 3523\n"
     ]
    }
   ],
   "source": [
    "len_tok = tokenized.apply(lambda x: len(x))\n",
    "print('We need to delete',len_tok[len_tok>512].count())\n",
    "index_to_drop = len_tok[len_tok>512].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "toxic_comm_dataset= toxic_comm_dataset.drop(index_to_drop).reset_index(drop=True)\n",
    "tokenized = tokenized.drop(index_to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0         [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n1         [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n2         [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n3         [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n4         [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n                                ...                        \n156043    [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...\n156044    [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...\n156045    [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...\n156046    [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...\n156047    [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...\nName: text, Length: 156048, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = toxic_comm_dataset['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Down Sampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def down_sampling(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=state)] + [features_ones]\n",
    "        )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=state)] + [target_ones]\n",
    "        )\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=state)\n",
    "\n",
    "    return features_downsampled.reset_index(drop=True), target_downsampled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_downsampled, target_downsapled = down_sampling(tokenized, target, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(map(len, tokenized_downsampled))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Adding zeros*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_zeros(zeros):\n",
    "    zeros = np.array(zeros + [0]*(max_len - len(zeros)))\n",
    "    return zeros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding zeros to arrays with smaller len."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Padding and Masks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_downsampled = tokenized_downsampled.apply(add_zeros).to_numpy()\n",
    "\n",
    "padded = np.zeros((len(tokenized_downsampled), len(tokenized_downsampled[0])))\n",
    "\n",
    "for i in range(len(tokenized_downsampled)):\n",
    "    padded[i,:] = tokenized_downsampled[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(36904, 512)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(36904, 512)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*BERT(using CUDA to run code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.10.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using GPU to run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Takes a lot of time(without CUDA)'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Takes a lot of time(without CUDA)'''\n",
    "# batch_size = 20\n",
    "# embeddings = []\n",
    "#\n",
    "# for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "#     batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "#     attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "#\n",
    "#     embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1845 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c64d5f12edb4b5cafabb50b9307e320"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Takes around 2h(with CUDA)'''\n",
    "batch_size = 20\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // (batch_size))):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(36900, 768)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(36904,)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsapled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = list(range(0, features.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_downsampled = target_downsapled[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(36900,)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Split Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target_downsampled, test_size=0.3, random_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conclusion\n",
    "We did:\n",
    "\n",
    "Tokenization.<br>\n",
    "Cut text more than 512 characters.<br>\n",
    "Made downsaplimg.<br>\n",
    "Padding and Masks.<br>\n",
    "Embedding\n",
    "Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Models<a href='models'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Cross Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cr_val_sc(model, features, target):\n",
    "    score = cross_val_score(model, features, target, cv=5, scoring = 'f1')\n",
    "    final_score = score.mean()\n",
    "    return print('f1 is: ',final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression(solver='sag')\n",
    "model_forest = RandomForestClassifier(random_state=state, n_jobs=-1)\n",
    "model_tree =  DecisionTreeClassifier(random_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Linear Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galina Rusinova\\miniconda3\\envs\\12_ml_for_texts\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Galina Rusinova\\miniconda3\\envs\\12_ml_for_texts\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Galina Rusinova\\miniconda3\\envs\\12_ml_for_texts\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Galina Rusinova\\miniconda3\\envs\\12_ml_for_texts\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 is:  0.8754422728495781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galina Rusinova\\miniconda3\\envs\\12_ml_for_texts\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "cr_val_sc(model_logistic, features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_forest = {\n",
    "    'n_estimators': list(range(50,300,50)),\n",
    "    'max_depth':[5,15],\n",
    "    'max_features' : list(range(1,20, 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_tree = {\n",
    "    'max_depth':list(range(1,20))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Search for better parameters and f1 score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=123456),\n             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n                                       13, 14, 15, 16, 17, 18, 19]},\n             scoring='f1')"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_tree = GridSearchCV(model_tree,\n",
    "                       param_grid=params_tree,\n",
    "                       scoring = 'f1',\n",
    "                       cv=5)\n",
    "\n",
    "CV_tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1_score: 0.749796238357133\n",
      "With parameters {'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "print('The best f1_score:', CV_tree.best_score_)\n",
    "print('With parameters', CV_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=RandomForestClassifier(n_jobs=-1, random_state=123456),\n             param_grid={'max_depth': [5, 15],\n                         'max_features': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n                         'n_estimators': [50, 100, 150, 200, 250]},\n             scoring='f1')"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_forest = GridSearchCV(model_forest,\n",
    "                         param_grid=params_forest,\n",
    "                         scoring='f1',\n",
    "                         cv=5)\n",
    "\n",
    "CV_forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1_score: 0.8282004239334325\n",
      "With parameters {'max_depth': 15, 'max_features': 15, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "print('The best f1_score:', CV_forest.best_score_)\n",
    "print('With parameters', CV_forest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "|Model| F1|\n",
    "|---|---|\n",
    "|LR|0.875|\n",
    "|RFC|0.829|\n",
    "|DTC|0.750|\n",
    "\n",
    "The best model is Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training Best Model on Test Set<a href='test_set'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_best = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galina Rusinova\\miniconda3\\envs\\12_ml_for_texts\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for Train Set:  0.890666422890575\n"
     ]
    }
   ],
   "source": [
    "prediction_train = model_best.predict(features_train)\n",
    "print('f1_score for Train Set: ', f1_score(target_train, prediction_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for Train Set:  0.8719512195121951\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model_best.predict(features_test)\n",
    "print('f1_score for Train Set: ', f1_score(target_test, prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion<a href='conclusion'></a>\n",
    "\n",
    "|Set| F1|\n",
    "|---|---|\n",
    "|Train|0.890|\n",
    "|Test|0.872|\n",
    "\n",
    "There is no difference in f1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}